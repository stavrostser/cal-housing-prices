{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Variables =========\n",
    "\n",
    "# Fill in the variables below and run cell first\n",
    "# Note: Use forward slashes / instead of backslashes \\ in file paths\n",
    "\n",
    "DATASET_FOR_MODEL_CSV_FILE_PATH = 'C:/cal-housing-prices/dataset/dataset.csv'\n",
    "\n",
    "TRAINING_SET_CSV_FILE_PATH = 'C:/cal-housing-prices/dataset/training_set.csv'\n",
    "TEST_SET_CSV_FILE_PATH = 'C:/cal-housing-prices/dataset/test_set.csv'\n",
    "TEST_SET_SIZE = 0.1  # fraction of the dataset to be used as test set\n",
    "\n",
    "RANDOM_SEED = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Libraries =========\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= CustomDataset class =========\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)  # Set the random seed in PyTorch for reproducibility\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for handling data directly from a pandas dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        # Assuming the last column is the output/target\n",
    "        data = torch.tensor(row[:-1].values, dtype=torch.float32)\n",
    "        target = torch.tensor(row[-1], dtype=torch.float32)\n",
    "        return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Create Training and Test sets =========\n",
    "\n",
    "# Load dataset into a pandas DataFrame\n",
    "df = pd.read_csv(DATASET_FOR_MODEL_CSV_FILE_PATH)\n",
    "\n",
    "# Separate a Test set and keep it aside\n",
    "dfTest = df.sample(frac=TEST_SET_SIZE, axis='index', random_state=RANDOM_SEED) # random_state parameter is included for reproducibility\n",
    "df = df.drop(dfTest.index) # the remaining data is used as the training set\n",
    "\n",
    "# Save the Training and Test sets to CSV files\n",
    "df.to_csv(TRAINING_SET_CSV_FILE_PATH, index=False)\n",
    "dfTest.to_csv(TEST_SET_CSV_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Neural Network and Training classes =========\n",
    "\n",
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self, input_size=3, output_size=1, neurons=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, neurons)\n",
    "        self.fc2 = torch.nn.Linear(neurons, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"input: \", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # print(\"output: \", x.shape)\n",
    "        return x\n",
    "    \n",
    "class NeuralNetworkRegressor:\n",
    "    def __init__(self, input_size=5, output_size=1, neurons=10, learning_rate=0.001, batch_size=32, epochs=100):\n",
    "        self.norm_params = {}\n",
    "        self.model = SimpleNN(input_size=input_size, output_size=output_size, neurons=neurons)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.loss_function = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def normalize(self, dataframe, train=False):\n",
    "        # Min-Max Normalization\n",
    "        for column in dataframe.columns:\n",
    "            min_value = dataframe[column].min() if train else self.norm_params[column][0]\n",
    "            max_value = dataframe[column].max() if train else self.norm_params[column][1]\n",
    "            if train:\n",
    "                self.norm_params[column] = (min_value, max_value)\n",
    "            dataframe[column] = (dataframe[column] - min_value) / (max_value - min_value)\n",
    "        return dataframe\n",
    "    \n",
    "    def denormalize(self, dataframe):\n",
    "        # Min-Max De-normalization\n",
    "        for column in dataframe.columns:\n",
    "            min_value, max_value = self.norm_params[column]\n",
    "            dataframe[column] = dataframe[column] * (max_value - min_value) + min_value\n",
    "        return dataframe\n",
    "\n",
    "    def train(self, dataframe):\n",
    "\n",
    "        dataframe = self.normalize(dataframe.copy(), train=True)\n",
    "        dataset = CustomDataset(dataframe)\n",
    "        train_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "\n",
    "            for data, target in train_loader:\n",
    "\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                # print(data.shape, target.shape)\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.loss_function(output, target.view(-1, 1))\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch: {epoch + 1}, Loss: {total_loss}\")\n",
    "\n",
    "    def predict(self, dataframe):\n",
    "        # assume the last column in the dataframe is the target initialized to 0 and will be replaced by the prediction\n",
    "        dataframe = self.normalize(dataframe, train=False)\n",
    "        dataset = CustomDataset(dataframe)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for i in range(len(dataset)):\n",
    "            data, _ = dataset[i]\n",
    "            data = data.to(self.device)\n",
    "            output = self.model(data)\n",
    "            dataframe.iloc[i, -1] = output.item()\n",
    "\n",
    "        dataframe = self.denormalize(dataframe)\n",
    "        return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Load Training and Test sets =========\n",
    "\n",
    "# Load the Training set into a pandas dataframe\n",
    "dfTraining = pd.read_csv(TRAINING_SET_CSV_FILE_PATH)\n",
    "\n",
    "# Load the Test set into a pandas dataframe\n",
    "dfTest = pd.read_csv(TEST_SET_CSV_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Training =========\n",
    "\n",
    "model = NeuralNetworkRegressor(input_size=5, output_size=1, neurons=100, learning_rate=0.001, batch_size=32, epochs=100)\n",
    "\n",
    "model.train(dfTraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a copy of dfTraining to keep the original data\n",
    "dfPredict = dfTraining.copy()\n",
    "\n",
    "model.predict(dfPredict)\n",
    "\n",
    "# plot the test target vs prediction in scatter plot. also plot the y = x line\n",
    "plt.scatter(df.iloc[:,-1], dfPredict.iloc[:,-1], s=5, marker='o')\n",
    "plt.plot([0, df.iloc[:,-1].max()], [0, df.iloc[:,-1].max()], color='black', linewidth=1)\n",
    "plt.title(\"Training Set\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a copy of dfTest to keep the original data\n",
    "dfTestPredict = dfTest.copy()\n",
    "\n",
    "model.predict(dfTestPredict)\n",
    "\n",
    "# plot the test target vs prediction in scatter plot. also plot the y = x line\n",
    "plt.scatter(dfTest.iloc[:,-1], dfTestPredict.iloc[:,-1], s=5, marker='o')\n",
    "plt.plot([0, dfTest.iloc[:,-1].max()], [0, dfTest.iloc[:,-1].max()], color='black', linewidth=1)\n",
    "plt.title(\"Test Set\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
